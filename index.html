<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Optical illusions zero-shot from diffusion models.">
  <meta name="keywords" content="Diffusion, Illusions, Optical Illusions">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Visual Anagrams</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-8P4QSMJ1ZN"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-8P4QSMJ1ZN');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!--<link rel="icon" href="./static/images/favicon.svg">-->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <!-- Enable smooth scrolling for only main page -->
  <style>
    html {
      scroll-behavior: smooth;
    }
  </style>

</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Visual Anagrams: Generating Multi-View Optical Illusions with Diffusion Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://dangeng.github.io" target="_blank">Daniel Geng</a>,</span>
            <span class="author-block">
              <a href="https://inbumpark.github.io/" target="_blank">Inbum Park</a>,</span>
            <span class="author-block">
              <a href="https://andrewowens.com" target="_blank">Andrew Owens</a></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">University of Michigan</span>
          </div>

          <div class="is-size-6 publication-authors">
            <span class="author-block">Correspondence to: <span class='rev'>ude.hcimu@gnegd</span></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2311.17919"
                   target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2311.17919"
                   target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!--
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video (Coming Soon)</span>
                </a>
              </span>
              -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/dangeng/visual_anagrams"
                   target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Colab Link. -->
              <span class="link-block">
                <a href="https://colab.research.google.com/drive/1hCvJR5GsQrhH1ceDjdbzLG8y6m2UdJ6l?usp=sharing"
                   target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-book"></i>
                  </span>
                  <span>Colab</span>
                  </a>
              </span>
              <!-- Cutout Link. -->
              <span class="link-block">
                <a href="./static/assets/jigsaw.pdf"
                   target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-puzzle-piece"></i>
                  </span>
                  <span>Print a Jigsaw!</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- TEASER + INTRO -->
<section class="hero teaser">
  <h2 class="subtitle has-text-centered">
    <b>tl;dr:</b> We use pretrained diffusion models<br>to make optical illusions
  </h2>
  <div class="is-centered is-max-desktop teaser">
    <video class="teaser-video" autoplay muted loop playsinline>
      <source src="./static/videos/website_teaser.256.mp4"
              type="video/mp4">
    </video>
  </div>
</section>


<!-- OVERVIEW -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
          We present a simple, zero-shot method to generate <i>multi-view optical illusions</i>. 
          These are images that look like one thing, but change appearance or identity when
          transformed. We <a href="#method">show in theory</a> and practice that our method supports a broad range of transformations 
          including <a href="#rot90_examples">rotations</a>, <a href="#flip_examples">flips</a>, 
          <a href="#inversion_examples">color inversions</a>, <a href="#misc_examples">skews</a>, 
          <a href="#jigsaw_examples">jigsaw rearrangements</a>, 
          <a href="#perm_examples">random permutations</a>, and
          <a href="#triple_examples">multiple views</a>.
          We show some examples below.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- JIGSAW GRID -->
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3" id="jigsaw_examples">Jigsaw Permutations</h2>
    </div>
    <div class="columns is-centered">
      <video class="grid-video" autoplay muted loop playsinline>
        <source src="./static/videos/viz/jigsaw.1.mp4"
                type="video/mp4">
      </video>
    </div>
    <div class="columns is-centered">
      <video class="grid-video" autoplay muted loop playsinline>
        <source src="./static/videos/viz/jigsaw.2.mp4"
                type="video/mp4">
      </video>
    </div>
    <div class="columns is-centered">
      <video class="grid-video" autoplay muted loop playsinline>
        <source src="./static/videos/viz/jigsaw.3.mp4"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>

<!-- FLIPS GRID -->
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3" id="flip_examples">Flips and 180° Rotations</h2>
    </div>
    <div class="columns is-centered">
      <video class="grid-video" autoplay muted loop playsinline>
        <source src="./static/videos/viz/flips.1.mp4"
                type="video/mp4">
      </video>
    </div>
    <div class="columns is-centered">
      <video class="grid-video" autoplay muted loop playsinline>
        <source src="./static/videos/viz/flips.2.mp4"
                type="video/mp4">
      </video>
    </div>
    <div class="columns is-centered">
      <video class="grid-video" autoplay muted loop playsinline>
        <source src="./static/videos/viz/flips.3.mp4"
                type="video/mp4">
      </video>
    </div>
    <div class="columns is-centered">
      <video class="grid-video" autoplay muted loop playsinline>
        <source src="./static/videos/viz/flips.4.mp4"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>

<!-- 90 DEGREE GRID -->
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3" id="rot90_examples">90° Rotations</h2>
    </div>
    <div class="columns is-centered">
      <video class="grid-video" autoplay muted loop playsinline>
        <source src="./static/videos/viz/rotate.1.mp4"
                type="video/mp4">
      </video>
    </div>
    <div class="columns is-centered">
      <video class="grid-video" autoplay muted loop playsinline>
        <source src="./static/videos/viz/rotate.2.mp4"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>

<!-- INVERSIONS GRID -->
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3" id="inversion_examples">Color Inversions</h2>
    </div>
    <div class="columns is-centered">
      <video class="grid-video" autoplay muted loop playsinline>
        <source src="./static/videos/viz/invert.1.mp4"
                type="video/mp4">
      </video>
    </div>
    <div class="columns is-centered">
      <video class="grid-video" autoplay muted loop playsinline>
        <source src="./static/videos/viz/invert.2.mp4"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>

<!-- MISC GRID -->
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3" id="misc_examples">Miscellaneous Transformations</h2>
    </div>
    <div class="columns is-centered">
      <video class="grid-video" autoplay muted loop playsinline>
        <source src="./static/videos/viz/misc.1.mp4"
                type="video/mp4">
      </video>
    </div>
    <div class="columns is-centered">
      <video class="grid-video" autoplay muted loop playsinline>
        <source src="./static/videos/viz/misc.2.mp4"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>

<!-- PATCH GRID -->
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3" id="perm_examples">Random Patch Permutations</h2>
    </div>
    <div class="columns is-centered">
      <video class="grid-video" autoplay muted loop playsinline>
        <source src="./static/videos/viz/patch.1.mp4"
                type="video/mp4">
      </video>
    </div>  
    <div class="columns is-centered">
      <video class="grid-video" autoplay muted loop playsinline>
        <source src="./static/videos/viz/patch.2.mp4"
                type="video/mp4">
      </video>
    </div>  
  </div>
</section>

<!-- THREE VIEW GRID -->
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3" id="triple_examples">Three Views</h2>
    </div>
    <div class="columns is-centered">
      <video class="grid-video" autoplay muted loop playsinline>
        <source src="./static/videos/viz/3view.mp4"
                type="video/mp4">
      </video>
    </div>  
  </div>
</section>

<!-- FOUR VIEW GRID -->
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3" id="quadruple_examples">Four Views</h2>
    </div>
    <div class="columns is-centered">
      <video class="grid-video" autoplay muted loop playsinline>
        <source src="./static/videos/viz/4view.mp4"
                type="video/mp4">
      </video>
    </div>  
  </div>
</section>

<!-- METHOD -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered" id="method">Method</h2>
        <div class="content has-text-justified">
          <img src="./static/images/method.jpg" class="center-img"/>
          <p>
            Our method is conceptually simple. We take an off-the-shelf diffusion model and use it
            to estimate the noise in different views or transformations, \(v_i\), of an image. 
            The noise estimates are then aligned by applying the inverse view, \(v_i^{-1}\),
            and averaged together. This averaged noise estimate is then used to take a diffusion step.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- CONDITIONS -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">Conditions on Views</h2>
        <div class="content has-text-justified">
          <p>
            We find that not every view function works with the above method. Of course, \(v_i\) must
            be invertible, but we discuss two additional constraints.
          </p>
        </div>
        <h2 class="title is-4">Linearity</h2>
        <div class="content has-text-justified">
          <p>
            A diffusion model is trained to estimate the noise in noisy data \(\mathbf{x}_t\) conditioned 
            on time step \(t\). The noisy data \(\mathbf{x}_t\) is expected to have the form 
            \[\mathbf{x}_t = w_t^{\text{signal}}\underbrace{\mathbf{x}_0}_{\text{signal}} + w_t^{\text{noise}}\underbrace{\epsilon\vphantom{\mathbf{x}_0}}_{\text{noise}}.\]
            That is, \(\mathbf{x}_t\) is a weighted average of pure signal \(\mathbf{x_0}\) 
            and pure noise \(\epsilon\), specifically with weights \(w_t^{\text{signal}}\) and \(w_t^{\text{noise}}\). 
            Therefore, our view, \(v\) must maintain this weighting between signal and noise. This can be achieved
            by making \(v\) linear, which we represent by the square matrix \(\mathbf{A}\). By linearity
            \[\begin{aligned} v(\mathbf{x}_t) &= \mathbf{A}(w_t^{\text{signal}} \mathbf{x}_0+w_t^{\text{noise}} \epsilon)\\[7pt] &= w_t^{\text{signal}} \underbrace{\mathbf{A}\mathbf{x}_0}_{\text{new signal}} + w_t^{\text{noise}} \underbrace{\mathbf{A}\epsilon}_{\text{new noise}}. \end{aligned}\]
            Effectively, \(v\) acts on the signal and the noise independently, and combines the result with the correct weighting.
          </p>
        </div>
        <h2 class="title is-4">Statistical Consistency</h2>
        <div class="content has-text-justified">
          <p>
            Diffusion models are trained with the assumption that the noise is drawn iid from a standard normal.
            Therefore we must ensure that the transformed noise also follows these statistics. That is, we need
            \[\mathbf{A}\epsilon \sim \mathcal{N}(0, I).\]
            For linear transformations, this is equivalent to the condition that \(\mathbf{A}\) is orthogonal.
            Intuitively, orthogonal matrices respect the spherical symmetry of the standard multivariate Gaussian distribution.
          </p>
          <p>
            Therefore, for a transformation to work with our method, it is <b>sufficient for it to be orthogonal.</b>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- ORTHOGONAL -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">Orthogonal Transformations</h2>
        <div class="content has-text-justified">
          <p>
            Most orthogonal transformations on images are meaningless, visually. For example, we transform
            the image below with a randomly sampled orthogonal matrix.
          </p>
        </div>
        <div class="content has-text-justified">
          <img src="./static/images/orthogonal.jpeg" class="center-img"/>
        </div>
        <div class="content has-text-justified">
          <p>
            However, <b>permutations matrices are a subset of orthogonal matrices,</b> and are quite interpretable. 
            They are just rearrangements of pixels in an image. This is where the idea of a <b>visual anagram</b>
            comes from. The majority of illusions here can be interpreted this way—as specific rearrangements of pixels—such as
            <a href="#rot90_examples">rotations</a>, <a href="#flip_examples">flips</a>, 
            <a href="#misc_examples">skews</a>, <a href="#misc_examples">"inner rotations,"</a> 
            <a href="#jigsaw_examples">jigsaw rearrangements</a>, and 
            <a href="#perm_examples">patch permutations</a>. Finally, <a href="#inversion_examples">color inversions</a>
            are not permutations, but are orthogonal as they are a negation of pixel values.
            
          </p>
        </div>
      </div>
    </div>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There are several other great works in this area:
          </p>
          <p>
            <a href="https://diffusionillusions.com/" target="_blank">Diffusion Illusions</a>, 
            by <a href="https://ryanndagreat.github.io/" target="_blank">Ryan Burgert</a> <i>et al.</i>,
            which produces multi-view illusions, along with other visual effects, through score distillation sampling.
          </p>
          <p>
            This <a href="https://github.com/tancik/Illusion-Diffusion" target="_blank">colab notebook</a> by 
            <a href="https://www.matthewtancik.com/about-me" target="_blank">Matthew Tancik</a>, 
            which introduces a similar idea to ours. We improve upon it significantly in 
            terms of quality of illusions, range of transformations, and theoretical analysis.
          </p>
          <p>
            <a href="https://www.reddit.com/r/StableDiffusion/comments/16ew9fz/spiral_town_different_approach_to_qr_monster/" target="_blank">Recent work by a pseudonymous artist</a>, Ugleh,
            uses a Stable Diffusion model finetuned for generating QR codes to produce images whose global structure subtly matches a given template image.
          </p>
          <p>
            <a href="https://dangeng.github.io/factorized_diffusion/" target="_blank">Factorized Diffusion</a>, 
            follow up work to Visual Anagrams which makes many different types of "hybrid" illusions, including 
            hybrid images with three different contents, partially resolving an open problem from the 
            <a href="https://stanford.edu/class/ee367/reading/OlivaTorralb_Hybrid_Siggraph06.pdf" target="_blank">
            original hybrid images paper</a> (see section 2.3).
          </p>
          <p>
            <a href="https://ificl.github.io/images-that-sound/" target="_blank">Images that Sound</a>, 
            which creates spectrograms that also look like images using a similar technique, but across modalities.
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{geng2023visualanagrams,
  title     = {Visual Anagrams: Generating Multi-View Optical Illusions with Diffusion Models},
  author    = {Geng, Daniel and Park, Inbum and Owens, Andrew},
  journal   = {arXiv:2311.17919},
  year      = {2023},
  month     = {November},
  abbr      = {Preprint},
  url       = {https://arxiv.org/abs/2311.17919},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a 
            <a rel="license" 
            href="http://creativecommons.org/licenses/by-sa/4.0/"
            target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>, 
            and is written by <a href="https://keunhong.com/" target="_blank">
            Keunhong Park</a> for the <a href="https://nerfies.github.io/" 
            target="_blank">Nerfies</a> project. You are free to use the 
            <a href="https://github.com/nerfies/nerfies.github.io"
            target="_blank">source code</a> of this website,
            but please keep these links in the footer, 
            as requested by the authors.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
